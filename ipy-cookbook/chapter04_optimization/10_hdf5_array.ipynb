{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5とPyTablesによる巨大配列の操作\n",
    "　NumPy配列等の配列データを永続化する方法を考える。配列の要素数が小さい場合、np.savetxt,np.save,np.savezなどNumPy組み込みの関数で処理できる。しかし要素数が10億を超える配列は、メモリに読み込むには巨大すぎる。\n",
    " \n",
    "　その代替策がメモリマップだ。配列はファイルに格納され、CPUが必要となった部分が選択的にメモリに読み込まれる(オーバーレイ?)。\n",
    "  \n",
    "　ここでは、巨大なデータセットを扱うためのデザインされたPyTablesを使う。これは、[HDF5(Hierarchical Data Format)](https://support.hdfgroup.org/HDF5/)と呼ばれる広く使われているオープンなファイルフォーマットを通して高速なメモリマップを実装している。HDF5ファイルは、POSIX風の階層構造の中に複数のデータセットを格納できる。不必要なシステムメモリの消費を避けながら、データセットのどの部分でも効率的で簡単なアクセスが可能。\n",
    " \n",
    "## 準備\n",
    "　PyTables3.0以降が必要。Anacondaを使用している場合、\n",
    "```\n",
    "conda install tables\n",
    "```\n",
    "でPyTablesをインストールできる。\n",
    "\n",
    "## 手順\n",
    "\n",
    "### NumPyとPyTablesのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tables as tb # tabels for hdf5 file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 空のHDF5ファイルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The file 'myfile.h5' is already opened.  Please close it before reopening in write mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-12ffbab22357>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'myfile.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntum/anaconda3/lib/python3.6/site-packages/tables/file.py\u001b[0m in \u001b[0;36mopen_file\u001b[0;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m                 raise ValueError(\n\u001b[1;32m    316\u001b[0m                     \u001b[0;34m\"The file '%s' is already opened.  Please \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                     \"close it before reopening in write mode.\" % filename)\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;31m# Finally, create the File instance, and return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The file 'myfile.h5' is already opened.  Please close it before reopening in write mode."
     ]
    }
   ],
   "source": [
    "f = tb.open_file('myfile.h5', 'w') # 書き込み権限でmyfile.h5を開く"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 階層のトップレベルグループexperiment1を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NodeError",
     "evalue": "group ``/`` already has a child node named ``experiment1``",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNodeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c3d74e34e27a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'experiment1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntum/anaconda3/lib/python3.6/site-packages/tables/file.py\u001b[0m in \u001b[0;36mcreate_group\u001b[0;34m(self, where, name, title, filters, createparents)\u001b[0m\n\u001b[1;32m    946\u001b[0m         \u001b[0m_checkfilters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         return Group(parentnode, name,\n\u001b[0;32m--> 948\u001b[0;31m                      title=title, new=True, filters=filters)\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntum/anaconda3/lib/python3.6/site-packages/tables/group.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parentnode, name, title, new, filters, _log)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;31m# Finally, set up this object as a node.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparentnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_g_post_init_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntum/anaconda3/lib/python3.6/site-packages/tables/node.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parentnode, name, _log)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;31m# Only new nodes need to be referenced.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0;31m# Opened nodes are already known by their parent group.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mparentnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_refnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_set_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparentnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntum/anaconda3/lib/python3.6/site-packages/tables/group.py\u001b[0m in \u001b[0;36m_g_refnode\u001b[0;34m(self, childnode, childname, validate)\u001b[0m\n\u001b[1;32m    514\u001b[0m             raise NodeError(\n\u001b[1;32m    515\u001b[0m                 \u001b[0;34m\"group ``%s`` already has a child node named ``%s``\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m                 % (self._v_pathname, childname))\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;31m# Show a warning if there is an object attribute with that name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNodeError\u001b[0m: group ``/`` already has a child node named ``experiment1``"
     ]
    }
   ],
   "source": [
    "f.create_group('/', 'experiment1') # ファイル内に\"/experiment1\"を作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experiment1にメタデータを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.set_node_attr('/experiment1', 'data', '2014-09-01') # data要素としてデータを1つ代入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### グループ内に、1000＊1000の配列array1を格納\n",
    "　配列(array)を、階層'/experiment1'内に、配列名'array1'として、xの配列を格納する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/experiment1/array1 (Array(1000, 1000)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.rand(1000, 1000) # 1000*1000のスケールで、ランダムデータを入れた、numpy配列を作成\n",
    "f.create_array('/experiment1', 'array1', x) # 階層名、配列名、格納する配列内容(NumPy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ファイルをクローズして、変更をコミット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存HDF5ファイルをオープン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = tb.open_file('myfile.h5', 'r') # 読み込み権限でh5ファイルを開く"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data要素を取り出してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2014-09-01'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.get_node_attr('/experiment1', 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ファイル内パス指定、アクセス\n",
    "　ルート(/)を起点としてファイル内のパスにアクセスできる。rootから\"/\"を\".\"に置き換えてパス指定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tables.array.Array"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = f.root.experiment1.array1\n",
    "# /experiment1/array1\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配列の操作性\n",
    "　NumPyの配列としても操作可能。通常のNumPy配列よりメモリの使用効率は高くなる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(x[0,:], y[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 絶対パスの利点\n",
    "　ノードのパスが実行時に判明するような状況では、絶対パスからノードにアクセスする方法が有効となる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/experiment1/array1 (Array(1000, 1000)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := None"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.get_node('/experiment1/array1') # 階層/配列名で配列を指定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更新＆ファイル削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove('myfile.h5') # ファイルの削除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解説\n",
    "　複数の配列を一つのファイルに格納できる。巨大な配列を階層構造の中で管理するような大きなプロジェクトでHDF5は活躍する。例えばNASAやNOAAのような科学技術団体などで広く使われている([団体例](www.hdfgroup.org/users.html))。\n",
    " \n",
    "　ノードはグループとデータセットに分かれる。HDF5は内部と外部へのリンクをサポートしている。この昨日は同じ実験やプロジェクトに関するデータを異なるファイルで管理する際に役立つ。\n",
    " \n",
    "　NumPyのスライス文法を使って、さまざまな形式で配列にアクセスできる。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
